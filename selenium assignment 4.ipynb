{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 . Scrape the details of most viewed videos on YouTube from Wikipedia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>video_name</th>\n",
       "      <th>artist</th>\n",
       "      <th>view</th>\n",
       "      <th>upload</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[22]</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>8.78</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[24]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>7.40</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[25]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>5.46</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[26]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.35</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[27]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.14</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[30]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.44</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Uptown Funk\"[31]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.20</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[32]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.15</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Bath Song\"[33]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.14</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Gangnam Style\"[34]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.09</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[36]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>3.92</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Sugar\"[37]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.48</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.44</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Dame Tu Cosita\"[39]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>3.39</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[40]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.37</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[41]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.32</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Thinking Out Loud\"[42]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.27</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Dark Horse\"[43]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.09</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Faded\"[44]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.08</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Wheels on the Bus\"[45]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.08</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Shake It Off\"[46]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3.07</td>\n",
       "      <td>August 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Lean On\"[47]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.05</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[48]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.05</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Bailando\"[49]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.04</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.01</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Mi Gente\"[51]</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>2.93</td>\n",
       "      <td>June 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Perfect\"[52]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>2.87</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[53]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>2.85</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Hello\"[54]</td>\n",
       "      <td>Adele</td>\n",
       "      <td>2.84</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Axel F\"[55]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>2.83</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank                                       video_name  \\\n",
       "0    1.                           \"Baby Shark Dance\"[22]   \n",
       "1    2.                                  \"Despacito\"[24]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[25]   \n",
       "3    4.                               \"Shape of You\"[26]   \n",
       "4    5.                              \"See You Again\"[27]   \n",
       "5    6.   \"Masha and the Bear – Recipe for Disaster\"[30]   \n",
       "6    7.                                \"Uptown Funk\"[31]   \n",
       "7    8.  \"Learning Colors – Colorful Eggs on a Farm\"[32]   \n",
       "8    9.                                  \"Bath Song\"[33]   \n",
       "9   10.                              \"Gangnam Style\"[34]   \n",
       "10  11.                \"Phonics Song with Two Words\"[36]   \n",
       "11  12.                                      \"Sugar\"[37]   \n",
       "12  13.                                      \"Sorry\"[38]   \n",
       "13  14.                             \"Dame Tu Cosita\"[39]   \n",
       "14  15.                                       \"Roar\"[40]   \n",
       "15  16.                             \"Counting Stars\"[41]   \n",
       "16  17.                          \"Thinking Out Loud\"[42]   \n",
       "17  18.                                 \"Dark Horse\"[43]   \n",
       "18  19.                                      \"Faded\"[44]   \n",
       "19  20.                          \"Wheels on the Bus\"[45]   \n",
       "20  21.                               \"Shake It Off\"[46]   \n",
       "21  22.                                    \"Lean On\"[47]   \n",
       "22  23.                             \"Girls Like You\"[48]   \n",
       "23  24.                                   \"Bailando\"[49]   \n",
       "24  25.                                 \"Let Her Go\"[50]   \n",
       "25  26.                                   \"Mi Gente\"[51]   \n",
       "26  27.                                    \"Perfect\"[52]   \n",
       "27  28.           \"Waka Waka (This Time for Africa)\"[53]   \n",
       "28  29.                                      \"Hello\"[54]   \n",
       "29  30.                                     \"Axel F\"[55]   \n",
       "\n",
       "                            artist  view             upload  \n",
       "0   Pinkfong Kids' Songs & Stories  8.78      June 17, 2016  \n",
       "1                       Luis Fonsi  7.40   January 12, 2017  \n",
       "2                      LooLoo Kids  5.46    October 8, 2016  \n",
       "3                       Ed Sheeran  5.35   January 30, 2017  \n",
       "4                      Wiz Khalifa  5.14      April 6, 2015  \n",
       "5                       Get Movies  4.44   January 31, 2012  \n",
       "6                      Mark Ronson  4.20  November 19, 2014  \n",
       "7                      Miroshka TV  4.15  February 27, 2018  \n",
       "8       Cocomelon – Nursery Rhymes  4.14        May 2, 2018  \n",
       "9                              Psy  4.09      July 15, 2012  \n",
       "10                       ChuChu TV  3.92      March 6, 2014  \n",
       "11                        Maroon 5  3.48   January 14, 2015  \n",
       "12                   Justin Bieber  3.44   October 22, 2015  \n",
       "13                       El Chombo  3.39      April 5, 2018  \n",
       "14                      Katy Perry  3.37  September 5, 2013  \n",
       "15                     OneRepublic  3.32       May 31, 2013  \n",
       "16                      Ed Sheeran  3.27    October 7, 2014  \n",
       "17                      Katy Perry  3.09  February 20, 2014  \n",
       "18                     Alan Walker  3.08   December 3, 2015  \n",
       "19      Cocomelon – Nursery Rhymes  3.08       May 24, 2018  \n",
       "20                    Taylor Swift  3.07    August 18, 2014  \n",
       "21                     Major Lazer  3.05     March 22, 2015  \n",
       "22                        Maroon 5  3.05       May 31, 2018  \n",
       "23                Enrique Iglesias  3.04     April 11, 2014  \n",
       "24                       Passenger  3.01      July 25, 2012  \n",
       "25                        J Balvin  2.93      June 29, 2017  \n",
       "26                      Ed Sheeran  2.87   November 9, 2017  \n",
       "27                         Shakira  2.85       June 4, 2010  \n",
       "28                           Adele  2.84   October 22, 2015  \n",
       "29                      Crazy Frog  2.83      June 16, 2009  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using selenium for webscraping and also using the exception handling\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "#chromeweb browser is used\n",
    "driver = webdriver.Chrome(\"Chromedriver.exe\")\n",
    "\n",
    "#wikipedia is used for webscraping\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)\n",
    "\n",
    "rank1 = driver.find_elements_by_xpath('//*[@id=\"mw-content-text\"]/div[1]/table[3]/tbody/tr/td[1]')\n",
    "rank1\n",
    "\n",
    "#rank is scraped\n",
    "\n",
    "rank=[]\n",
    "for i in rank1:\n",
    "    rank.append(i.text)\n",
    "rank\n",
    "\n",
    "video_name1 = driver.find_elements_by_xpath('//*[@id=\"mw-content-text\"]/div[1]/table[3]/tbody/tr/td[2]')\n",
    "video_name1\n",
    "\n",
    "#video name is scraped\n",
    "\n",
    "video_name=[]\n",
    "for i in video_name1:\n",
    "    video_name.append(i.text)\n",
    "video_name\n",
    "\n",
    "#artist name is webscraped\n",
    "artist1 = driver.find_elements_by_xpath('//*[@id=\"mw-content-text\"]/div[1]/table[3]/tbody/tr/td[3]')\n",
    "artist1\n",
    "\n",
    "artist = []\n",
    "for i in artist1:\n",
    "    artist.append(i.text)\n",
    "artist\n",
    "\n",
    "#no of views is scraped\n",
    "view1 = driver.find_elements_by_xpath('//*[@id=\"mw-content-text\"]/div[1]/table[3]/tbody/tr/td[4]')\n",
    "view1\n",
    "\n",
    "view = []\n",
    "for i in view1:\n",
    "    view.append(i.text)\n",
    "view\n",
    "\n",
    "upload1 = driver.find_elements_by_xpath('//*[@id=\"mw-content-text\"]/div[1]/table[3]/tbody/tr/td[5]')\n",
    "upload1\n",
    "#no of upload is scraped\n",
    "\n",
    "upload = []\n",
    "for i in upload1:\n",
    "    upload.append(i.text)\n",
    "upload\n",
    "\n",
    "print(len(rank))\n",
    "print(len(video_name))\n",
    "print(len(artist))\n",
    "print(len(view))\n",
    "print(len(upload))\n",
    "\n",
    "#dataframe is used \n",
    "df=pd.DataFrame({})\n",
    "df['rank']=rank\n",
    "df['video_name']=video_name\n",
    "df['artist']=artist\n",
    "df['view']=view\n",
    "df['upload']=upload\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Scrape the details team India’s international fixtures from bcci.tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=91.0.4472.106)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-82745e3f903c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mmatchtitle1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmatchtitle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mmatchtitle1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[0mmatchtitle1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m#matchtitle is scraped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mtext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;34m\"\"\"The text of the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_ELEMENT_TEXT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    631\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=91.0.4472.106)\n"
     ]
    }
   ],
   "source": [
    "##using selenium for webscraping and also using the exception handling\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "#chromeweb browser is used\n",
    "driver = webdriver.Chrome(\"Chromedriver.exe\")\n",
    "\n",
    "#bcci\n",
    "url = 'https://www.bcci.tv/'\n",
    "driver.get(url)\n",
    "\n",
    "inter = driver.find_elements_by_xpath('/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]')[0]\n",
    "\n",
    "#international button is clicked\n",
    "\n",
    "inter.click()\n",
    "\n",
    "#fixture button is clicked\n",
    "\n",
    "interfix = driver.find_elements_by_xpath('/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]/div/ul/li[1]/a')[0]\n",
    "\n",
    "interfix.click()\n",
    "\n",
    "matchtitle = driver.find_elements_by_xpath('/html/body/div[4]/div/div/div[2]/section/div/div/a/div[2]/div[1]/span[2]')\n",
    "\n",
    "matchtitle\n",
    "\n",
    "matchtitle1 = []\n",
    "for i in matchtitle:\n",
    "    matchtitle1.append(i.text)\n",
    "matchtitle1\n",
    "#matchtitle is scraped\n",
    "\n",
    "len(matchtitle1)\n",
    "\n",
    "place = driver.find_elements_by_xpath('/html/body/div[4]/div/div/div[2]/section/div/div/a/div[2]/div[2]/p/span')\n",
    "place\n",
    "\n",
    "place1 = []\n",
    "for i in place:\n",
    "    place1.append(i.text)\n",
    "place1\n",
    "#place have been scraped\n",
    "\n",
    "len(place1)\n",
    "\n",
    "#data scraped\n",
    "date = driver.find_elements_by_xpath('//span[@class=\"fixture__datetime tablet-only\"]')\n",
    "\n",
    "date1 = []\n",
    "for i in date:\n",
    "    date1.append(i.text)\n",
    "date1\n",
    "\n",
    "len(date1)\n",
    "\n",
    "df = pd.DataFrame({})\n",
    "df['matchtitle1'] = matchtitle1\n",
    "df['place'] = place1\n",
    "df['date & time'] = date1\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Scrape the details of selenium exception from guru99.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exception name</td>\n",
       "      <td>Description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firefo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidElementStateExceptio</td>\n",
       "      <td>It occurs when command can't be finished when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>It occurs when you afford to get the session w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExcep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an alert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver does n't sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name  \\\n",
       "0                        Exception name   \n",
       "1            ElementNotVisibleException   \n",
       "2         ElementNotSelectableException   \n",
       "3                NoSuchElementException   \n",
       "4                  NoSuchFrameException   \n",
       "5               NoAlertPresentException   \n",
       "6                 NoSuchWindowException   \n",
       "7        StaleElementReferenceException   \n",
       "8              SessionNotFoundException   \n",
       "9                      TimeoutException   \n",
       "10                   WebDriverException   \n",
       "11            ConnectionClosedException   \n",
       "12     ElementClickInterceptedException   \n",
       "13      ElementNotInteractableException   \n",
       "14             ErrorInResponseException   \n",
       "15  ErrorHandler.UnknownServerException   \n",
       "16         ImeActivationFailedException   \n",
       "17             ImeNotAvailableException   \n",
       "18         InsecureCertificateException   \n",
       "19             InvalidArgumentException   \n",
       "20         InvalidCookieDomainException   \n",
       "21          InvalidCoordinatesException   \n",
       "22          InvalidElementStateExceptio   \n",
       "23            InvalidSessionIdException   \n",
       "24       InvalidSwitchToTargetException   \n",
       "25                  JavascriptException   \n",
       "26                        JsonException   \n",
       "27             NoSuchAttributeException   \n",
       "28       MoveTargetOutOfBoundsException   \n",
       "29               NoSuchContextException   \n",
       "30                NoSuchCookieException   \n",
       "31                    NotFoundException   \n",
       "32          RemoteDriverServerException   \n",
       "33                  ScreenshotException   \n",
       "34           SessionNotCreatedException   \n",
       "35           UnableToSetCookieException   \n",
       "36           UnexpectedTagNameException   \n",
       "37              UnhandledAlertException   \n",
       "38      UnexpectedAlertPresentException   \n",
       "39               UnknownMethodException   \n",
       "40          UnreachableBrowserException   \n",
       "41          UnsupportedCommandException   \n",
       "\n",
       "                                          description  \n",
       "0                                         Description  \n",
       "1   This type of Selenium exception occurs when an...  \n",
       "2   This Selenium exception occurs when an element...  \n",
       "3   This Exception occurs if an element could not ...  \n",
       "4   This Exception occurs if the frame target to b...  \n",
       "5   This Exception occurs when you switch to no pr...  \n",
       "6   This Exception occurs if the window target to ...  \n",
       "7   This Selenium exception occurs happens when th...  \n",
       "8   The WebDriver is acting after you quit the bro...  \n",
       "9   Thrown when there is not enough time for a com...  \n",
       "10  This Exception takes place when the WebDriver ...  \n",
       "11  This type of Exception takes place when there ...  \n",
       "12  The command may not be completed as the elemen...  \n",
       "13  This Selenium exception is thrown when any ele...  \n",
       "14  This happens while interacting with the Firefo...  \n",
       "15  Exception is used as a placeholder in case if ...  \n",
       "16  This expectation will occur when IME engine ac...  \n",
       "17    It takes place when IME support is unavailable.  \n",
       "18  Navigation made the user agent to hit a certif...  \n",
       "19  It occurs when an argument does not belong to ...  \n",
       "20  This happens when you try to add a cookie unde...  \n",
       "21  This type of Exception matches an interacting ...  \n",
       "22  It occurs when command can't be finished when ...  \n",
       "23  This Exception took place when the given sessi...  \n",
       "24  This occurs when the frame or window target to...  \n",
       "25  This issue occurs while executing JavaScript g...  \n",
       "26  It occurs when you afford to get the session w...  \n",
       "27  This kind of Exception occurs when the attribu...  \n",
       "28  It takes place if the target provided to the A...  \n",
       "29           ContextAware does mobile device testing.  \n",
       "30  This Exception occurs when no cookie matching ...  \n",
       "31  This Exception is a subclass of WebDriverExcep...  \n",
       "32  This Selenium exception is thrown when the ser...  \n",
       "33            It is not possible to capture a screen.  \n",
       "34  It happens when a new session could not be suc...  \n",
       "35  This occurs if a driver is unable to set a coo...  \n",
       "36  Happens if a support class did not get a web e...  \n",
       "37  This expectation occurs when there is an alert...  \n",
       "38  It occurs when there is the appearance of an u...  \n",
       "39  This Exception happens when the requested comm...  \n",
       "40  This Exception occurs only when the browser is...  \n",
       "41  This occurs when remote WebDriver does n't sen...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using selenium for webscraping and also using the exception handling\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "#chromeweb browser is used\n",
    "driver = webdriver.Chrome(\"Chromedriver.exe\")\n",
    "\n",
    "#guru web site is used\n",
    "url = 'https://www.guru99.com/exception-handling-selenium.html'\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "name = driver.find_elements_by_xpath('//*[@id=\"g-mainbar\"]/div[1]/div/div/div/div/div/div[2]/table/tbody/tr/td[1]')\n",
    "name\n",
    "#name is scraped\n",
    "\n",
    "name1 = []\n",
    "for i in name:\n",
    "    name1.append(i.text)\n",
    "name1\n",
    "\n",
    "desc = driver.find_elements_by_xpath('//*[@id=\"g-mainbar\"]/div[1]/div/div/div/div/div/div[2]/table/tbody/tr/td[2]')\n",
    "desc\n",
    "\n",
    "desc1 = []\n",
    "for i in desc:\n",
    "    desc1.append(i.text)\n",
    "desc1\n",
    "#description is scraped\n",
    "\n",
    "print(len(name))\n",
    "print(len(desc))\n",
    "\n",
    "#dataframe is used\n",
    "df = pd.DataFrame({})\n",
    "df['name']=name1\n",
    "df['description']=desc1\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Scrape the details of State-wise GDP of India from statisticstime.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>state</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>share</th>\n",
       "      <th>gdp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank                      state  GSDP(18-19)   share     gdp1\n",
       "0     1                Maharashtra    2,632,792  13.94%  399.921\n",
       "1     2                 Tamil Nadu    1,630,208   8.63%  247.629\n",
       "2     3              Uttar Pradesh    1,584,764   8.39%  240.726\n",
       "3     4                    Gujarat    1,502,899   7.96%  228.290\n",
       "4     5                  Karnataka    1,493,127   7.91%  226.806\n",
       "5     6                West Bengal    1,089,898   5.77%  165.556\n",
       "6     7                  Rajasthan      942,586   4.99%  143.179\n",
       "7     8             Andhra Pradesh      862,957   4.57%  131.083\n",
       "8     9                  Telangana      861,031   4.56%  130.791\n",
       "9    10             Madhya Pradesh      809,592   4.29%  122.977\n",
       "10   11                     Kerala      781,653   4.14%  118.733\n",
       "11   12                      Delhi      774,870   4.10%  117.703\n",
       "12   13                    Haryana      734,163   3.89%  111.519\n",
       "13   14                      Bihar      530,363   2.81%   80.562\n",
       "14   15                     Punjab      526,376   2.79%   79.957\n",
       "15   16                     Odisha      487,805   2.58%   74.098\n",
       "16   17                      Assam      315,881   1.67%   47.982\n",
       "17   18               Chhattisgarh      304,063   1.61%   46.187\n",
       "18   19                  Jharkhand      297,204   1.57%   45.145\n",
       "19   20                Uttarakhand      245,895   1.30%   37.351\n",
       "20   21            Jammu & Kashmir      155,956   0.83%   23.690\n",
       "21   22           Himachal Pradesh      153,845   0.81%   23.369\n",
       "22   23                        Goa       73,170   0.39%   11.115\n",
       "23   24                    Tripura       49,845   0.26%    7.571\n",
       "24   25                 Chandigarh       42,114   0.22%    6.397\n",
       "25   26                 Puducherry       34,433   0.18%    5.230\n",
       "26   27                  Meghalaya       33,481   0.18%    5.086\n",
       "27   28                     Sikkim       28,723   0.15%    4.363\n",
       "28   29                    Manipur       27,870   0.15%    4.233\n",
       "29   30                   Nagaland       27,283   0.14%    4.144\n",
       "30   31          Arunachal Pradesh       24,603   0.13%    3.737\n",
       "31   32                    Mizoram       22,287   0.12%    3.385\n",
       "32   33  Andaman & Nicobar Islands            -       -        -"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using selenium for webscraping and also using the exception handling\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "##chromeweb browser is used\n",
    "driver = webdriver.Chrome(\"Chromedriver.exe\")\n",
    "\n",
    "#staticticstimes is used\n",
    "url = 'http://statisticstimes.com/economy/india/indian-states-gdp.php'\n",
    "driver.get(url)\n",
    "\n",
    "#state  is webscraped\n",
    "state = driver.find_elements_by_xpath('//*[@id=\"table_id\"]/tbody/tr/td[2]')\n",
    "state\n",
    "\n",
    "state1 = []\n",
    "for i in state:\n",
    "    state1.append(i.text)\n",
    "state1\n",
    "\n",
    "rank = driver.find_elements_by_xpath('//*[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "rank    \n",
    "#rank  is webscraped\n",
    "\n",
    "rank1 = []\n",
    "for i in rank:\n",
    "    rank1.append(i.text)\n",
    "rank1\n",
    "\n",
    "#gsdp1  is webscraped\n",
    "GSDP1 = driver.find_elements_by_xpath('//*[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "GSDP1 \n",
    "\n",
    "GSDP = []\n",
    "for i in GSDP1:\n",
    "    GSDP.append(i.text)\n",
    "GSDP\n",
    "\n",
    "#share is webscraped\n",
    "share = driver.find_elements_by_xpath('//*[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "share\n",
    "\n",
    "share1 = []\n",
    "for i in share:\n",
    "    share1.append(i.text)\n",
    "share1\n",
    "\n",
    "#gdp is webscraped\n",
    "gdp= driver.find_elements_by_xpath('//*[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "gdp\n",
    "\n",
    "gdp1 = []\n",
    "for i in gdp:\n",
    "    gdp1.append(i.text)\n",
    "gdp1\n",
    "\n",
    "\n",
    "print(len(state1))\n",
    "print(len(rank1))\n",
    "print(len(GSDP))\n",
    "print(len(share1))\n",
    "print(len(gdp1))\n",
    "\n",
    "#dataframe is used\n",
    "df = pd.DataFrame({})\n",
    "df['rank'] = rank1\n",
    "df['state'] = state1\n",
    "df[' GSDP(18-19)'] = GSDP\n",
    "df['share'] = share1\n",
    "df['gdp1'] = gdp1 \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Scrape the details of trending repositories on Github.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository_title</th>\n",
       "      <th>Repository_description</th>\n",
       "      <th>Contributors_count</th>\n",
       "      <th>Language_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nushell</td>\n",
       "      <td>A new type of shell</td>\n",
       "      <td>232</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thanos-io</td>\n",
       "      <td>Highly available Prometheus setup with long te...</td>\n",
       "      <td>8</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>keras-team</td>\n",
       "      <td>Deep Learning for humans</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vercel</td>\n",
       "      <td>The React Framework</td>\n",
       "      <td>322k</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chromium</td>\n",
       "      <td>The official GitHub mirror of the Chromium source</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>google</td>\n",
       "      <td>Libraries and tools to perform fully homomorph...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AkashSingh3031</td>\n",
       "      <td>This repository contains all the DSA (Data-Str...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>programthink</td>\n",
       "      <td>【编程随想】收藏的电子书清单（多个学科，含下载链接）</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vxunderground</td>\n",
       "      <td>Collection of malware source code for a variet...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>monyhar</td>\n",
       "      <td>梦弘浏览器 自主研发版本 - 完全自主研发，打破国外垄断，比 Chrome 快 600%。缺...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Repository_title                             Repository_description  \\\n",
       "0          nushell                                A new type of shell   \n",
       "1        thanos-io  Highly available Prometheus setup with long te...   \n",
       "2       keras-team                           Deep Learning for humans   \n",
       "3           vercel                                The React Framework   \n",
       "4         chromium  The official GitHub mirror of the Chromium source   \n",
       "5           google  Libraries and tools to perform fully homomorph...   \n",
       "6   AkashSingh3031  This repository contains all the DSA (Data-Str...   \n",
       "7     programthink                         【编程随想】收藏的电子书清单（多个学科，含下载链接）   \n",
       "8    vxunderground  Collection of malware source code for a variet...   \n",
       "9          monyhar  梦弘浏览器 自主研发版本 - 完全自主研发，打破国外垄断，比 Chrome 快 600%。缺...   \n",
       "\n",
       "  Contributors_count Language_used  \n",
       "0                232          Rust  \n",
       "1                  8             -  \n",
       "2                  -             -  \n",
       "3               322k             -  \n",
       "4                  -             -  \n",
       "5                  -             -  \n",
       "6                  -             -  \n",
       "7                  -             -  \n",
       "8                  -             -  \n",
       "9                  -             -  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using selenium for webscraping and also using the exception handling\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "#chromeweb browser is used\n",
    "driver = webdriver.Chrome(\"Chromedriver.exe\")\n",
    "\n",
    "#github is used\n",
    "url = 'https://github.com/'\n",
    "driver.get(url)\n",
    "\n",
    "#button is clicked\n",
    "button = driver.find_elements_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary')[0]\n",
    "\n",
    "button.click()\n",
    "\n",
    "#button is clicked\n",
    "\n",
    "button = driver.find_elements_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a')[0]\n",
    "\n",
    "button.click()\n",
    "\n",
    "#getting the url \n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath('//*[@id=\"js-pjax-container\"]/div[3]/div/div[2]/article/h1/a'):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "    \n",
    "    \n",
    "#declare the array\n",
    "Repository_title = []\n",
    "Repository_description = []\n",
    "Contributors_count = []\n",
    "Language_used = []\n",
    "\n",
    "#using for loop webscrapinf the data using exception handling\n",
    "for i in urls[:10]:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "        jobs=driver.find_element_by_xpath('//*[@id=\"js-repo-pjax-container\"]/div[1]/div[1]/div/h1/span[1]/a')\n",
    "        Repository_title.append(jobs.text)\n",
    "    except NoSuchElementException:\n",
    "        Repository_title.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        jobs_des=driver.find_element_by_xpath('//*[@id=\"repo-content-pjax-container\"]/div/div[2]/div[2]/div/div[1]/div/p')\n",
    "        Repository_description.append(jobs_des.text)\n",
    "    except NoSuchElementException:\n",
    "        Repository_description.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        jobs_com=driver.find_element_by_xpath('//*[@id=\"repo-content-pjax-container\"]/div/div[2]/div[2]/div/div[4]/div/h2/a/span')\n",
    "        Contributors_count.append(jobs_com.text)\n",
    "    except NoSuchElementException:\n",
    "        Contributors_count.append(\"-\")\n",
    "    \n",
    "    try:\n",
    "        jobs_loc=driver.find_element_by_xpath('//*[@id=\"repo-content-pjax-container\"]/div/div[2]/div[2]/div/div[5]/div/ul/li[1]/a/span[1]')\n",
    "        Language_used.append(jobs_loc.text)\n",
    "    except NoSuchElementException:\n",
    "        Language_used.append(\"-\")\n",
    "        \n",
    "        \n",
    "print(len(Repository_title))\n",
    "print(len(Repository_description))\n",
    "print(len(Contributors_count))\n",
    "print(len(Language_used))\n",
    "\n",
    "\n",
    "#dataframe is used\n",
    "df = pd.DataFrame({})\n",
    "\n",
    "df['Repository_title']=Repository_title\n",
    "df['Repository_description']=Repository_description\n",
    "df['Contributors_count']=Contributors_count\n",
    "df['Language_used']=Language_used\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Scrape the details of top 100 songs on billiboard.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>last_week_rank</th>\n",
       "      <th>peak</th>\n",
       "      <th>week_on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butter</td>\n",
       "      <td>BTS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good 4 U</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peaches</td>\n",
       "      <td>Justin Bieber Featuring Daniel Caesar &amp; Giveon</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leave The Door Open</td>\n",
       "      <td>Silk Sonic (Bruno Mars &amp; Anderson .Paak)</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Things A Man Oughta Know</td>\n",
       "      <td>Lainey Wilson</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Country Again</td>\n",
       "      <td>Thomas Rhett</td>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Drunk (And I Don't Wanna Go Home)</td>\n",
       "      <td>Elle King &amp; Miranda Lambert</td>\n",
       "      <td>92</td>\n",
       "      <td>79</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>If You Want To</td>\n",
       "      <td>Lil Baby &amp; Lil Durk</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Seeing Green</td>\n",
       "      <td>Nicki Minaj, Drake &amp; Lil Wayne</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 song  \\\n",
       "0                              Butter   \n",
       "1                            Good 4 U   \n",
       "2                          Levitating   \n",
       "3                             Peaches   \n",
       "4                 Leave The Door Open   \n",
       "..                                ...   \n",
       "95           Things A Man Oughta Know   \n",
       "96                      Country Again   \n",
       "97  Drunk (And I Don't Wanna Go Home)   \n",
       "98                     If You Want To   \n",
       "99                       Seeing Green   \n",
       "\n",
       "                                       artist_name last_week_rank peak  \\\n",
       "0                                              BTS              1    1   \n",
       "1                                   Olivia Rodrigo              2    1   \n",
       "2                        Dua Lipa Featuring DaBaby              3    2   \n",
       "3   Justin Bieber Featuring Daniel Caesar & Giveon              6    1   \n",
       "4         Silk Sonic (Bruno Mars & Anderson .Paak)              4    1   \n",
       "..                                             ...            ...  ...   \n",
       "95                                   Lainey Wilson             93   93   \n",
       "96                                    Thomas Rhett             89   73   \n",
       "97                     Elle King & Miranda Lambert             92   79   \n",
       "98                             Lil Baby & Lil Durk              -   99   \n",
       "99                  Nicki Minaj, Drake & Lil Wayne             67   12   \n",
       "\n",
       "   week_on_board  \n",
       "0              3  \n",
       "1              4  \n",
       "2             36  \n",
       "3             12  \n",
       "4             14  \n",
       "..           ...  \n",
       "95             4  \n",
       "96             6  \n",
       "97             7  \n",
       "98             1  \n",
       "99             4  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using selenium for webscraping and also using the exception handling\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "#chromeweb browser is used\n",
    "driver = webdriver.Chrome(\"Chromedriver.exe\")\n",
    "\n",
    "#billboard\n",
    "url = 'https://www.billboard.com/'\n",
    "driver.get(url)\n",
    "\n",
    "button = driver.find_elements_by_xpath('//*[@id=\"root\"]/div[2]/div[2]/header/div/ul/li[1]/a')[0]\n",
    "#button is clicked\n",
    "\n",
    "button.click()\n",
    "\n",
    "button2 = driver.find_elements_by_xpath('//*[@id=\"main\"]/div[2]/div/div[1]/a/div[2]/div[2]/div[1]')[0]\n",
    "\n",
    "#button is clicked\n",
    "\n",
    "button2.click()\n",
    "\n",
    "\n",
    "song = driver.find_elements_by_xpath('//span[@class=\"chart-element__information__song text--truncate color--primary\"]')\n",
    "\n",
    "#song is webscraped\n",
    "song\n",
    "\n",
    "song1 = []\n",
    "for i in song:\n",
    "    song1.append(i.text)\n",
    "song1\n",
    "\n",
    "artist_name = driver.find_elements_by_xpath('//span[@class=\"chart-element__information__artist text--truncate color--secondary\"]')\n",
    "\n",
    "artist_name1 = []\n",
    "for i in artist_name:\n",
    "    artist_name1.append(i.text)\n",
    "artist_name1\n",
    "\n",
    "last_week_rank = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--last\"]')\n",
    "\n",
    "last_week_rank1 = []\n",
    "for i in last_week_rank:\n",
    "    last_week_rank1.append(i.text)\n",
    "last_week_rank1\n",
    "\n",
    "peak = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--peak\"]')\n",
    "\n",
    "peak1 = []\n",
    "for i in peak:\n",
    "    peak1.append(i.text)\n",
    "peak1\n",
    "\n",
    "week_on_board = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--week\"]')\n",
    "\n",
    "week_on_board\n",
    "\n",
    "week_on_board1 = []\n",
    "for i in week_on_board:\n",
    "    week_on_board1.append(i.text)\n",
    "week_on_board1\n",
    "\n",
    "print(len(song1))\n",
    "print(len(artist_name1))\n",
    "print(len(last_week_rank1))\n",
    "print(len(peak1))\n",
    "print(len(week_on_board1))\n",
    "\n",
    "df = pd.DataFrame({})\n",
    "df['song'] = song1\n",
    "df['artist_name'] = artist_name1\n",
    "df['last_week_rank'] = last_week_rank1\n",
    "df['peak'] = peak1\n",
    "df['week_on_board'] = week_on_board1\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Scrape the details of Data science recruiters from naukri.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>desgination</th>\n",
       "      <th>company</th>\n",
       "      <th>skills_they_hire_for</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HR</td>\n",
       "      <td>HR</td>\n",
       "      <td></td>\n",
       "      <td>Us English Language, Msexcel Advanced</td>\n",
       "      <td>Coimbatore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ankur Agarwal</td>\n",
       "      <td>Resource Management</td>\n",
       "      <td></td>\n",
       "      <td>SAP, Permissions, Designer, Marketing, Manufac...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>victorious javin</td>\n",
       "      <td>Owner of the company</td>\n",
       "      <td></td>\n",
       "      <td>Excel, Word, Powerpoint, Data Management, Data...</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phanindra</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td></td>\n",
       "      <td>Data Management</td>\n",
       "      <td>Warangal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOKAMBA T H</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td></td>\n",
       "      <td>Advanced Excel, Vba, Sql, Mis Reporting, Dashb...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jose K Kurian</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td></td>\n",
       "      <td>Data Collection, Data Interpretation, Results ...</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Manisha Sahu</td>\n",
       "      <td>Senior HR Associate</td>\n",
       "      <td></td>\n",
       "      <td>Investment Banking, Technical Support, Bpo, Kp...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aamir Mian</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rohini Rajamani</td>\n",
       "      <td>HR Lead</td>\n",
       "      <td></td>\n",
       "      <td>BI and BA, HANA, BW, BO, Design Analytics, CMC...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>akash murthy</td>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td></td>\n",
       "      <td>Python, javascript, Java, MongoDB, AWS, Machin...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>srinivasan singh</td>\n",
       "      <td>Hiring Manager</td>\n",
       "      <td></td>\n",
       "      <td>Data Analyst, Ibm Infosphere, Erwin, Oracle Ed...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nova Maria Devasia</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td></td>\n",
       "      <td>Android, Java, Linux Kernel, Data Analyst</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Karthik</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td></td>\n",
       "      <td>Java, C, C++, Manual Testing, Automation Tetsi...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sandhya</td>\n",
       "      <td>Consultant Recruitment</td>\n",
       "      <td></td>\n",
       "      <td>Data Analyst, Principal Engineer, senior data ...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NSMX</td>\n",
       "      <td>HR</td>\n",
       "      <td></td>\n",
       "      <td>Survey Programming, Data Analyst, Sampling, Fi...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>J LAWRENCE SUJITH</td>\n",
       "      <td>Manager Recruitment</td>\n",
       "      <td></td>\n",
       "      <td>Our trustable companies</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Eminent</td>\n",
       "      <td>HR/Admin</td>\n",
       "      <td></td>\n",
       "      <td>Client Relationship, Technical Sales, Digital ...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ankur Dagar</td>\n",
       "      <td>Talent Aquisition Specialist</td>\n",
       "      <td></td>\n",
       "      <td>Analyst, Security Engineer, System Admin, Data...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Karthick Guruswamy</td>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td></td>\n",
       "      <td>Business Development, Business Analyst, Direct...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Dileep</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td></td>\n",
       "      <td>Opportunities for freshers., Jr. Data Analyst</td>\n",
       "      <td>Trivandrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Prashant K</td>\n",
       "      <td>Sr HR</td>\n",
       "      <td></td>\n",
       "      <td>Data Analyst, Statistical Analysis, Data Scien...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hr Manager</td>\n",
       "      <td>Hr Manager</td>\n",
       "      <td></td>\n",
       "      <td>Microsoft Word, Microsoft Excel, Search Engine...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Rekha Singh</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td></td>\n",
       "      <td>Information Technology, Software Development, ...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SG</td>\n",
       "      <td>Sr. HR Executive - Recruitment</td>\n",
       "      <td></td>\n",
       "      <td>Java, J2ee, .net c# asp.net sql server, oracle...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ramesh Chary Arravalli</td>\n",
       "      <td>Senior HR Executive</td>\n",
       "      <td></td>\n",
       "      <td>Ar Calling, Claims Adjudication, Process Assoc...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Blueberry Digital Labs</td>\n",
       "      <td>HR</td>\n",
       "      <td></td>\n",
       "      <td>Node.js, Html, Css, Nosql, Web Designing, Web ...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Abhinav Shrivastava</td>\n",
       "      <td>Business Head</td>\n",
       "      <td></td>\n",
       "      <td>Data Analytics, Data Analysis, Sales Operation...</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Durga Devi B</td>\n",
       "      <td>HR Generalist Assistant</td>\n",
       "      <td></td>\n",
       "      <td>Software Development, Data Analytics</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RIBBUN SOFTWARE PVT LTD</td>\n",
       "      <td>Administration Executive</td>\n",
       "      <td></td>\n",
       "      <td>Internet Surfing, Data Updation, Data Monitori...</td>\n",
       "      <td>Jaipur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Jayashree</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td></td>\n",
       "      <td>Data Analysis</td>\n",
       "      <td>Hosur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Shashikant Sethy</td>\n",
       "      <td>Head Operations</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Parthasarathy</td>\n",
       "      <td>Business Head</td>\n",
       "      <td></td>\n",
       "      <td>Excel, Word, Internet, English Typing</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Krishna Sain</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td></td>\n",
       "      <td>Data Science, Big Data, Big Data Analytics</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Venkat Ragavan</td>\n",
       "      <td>Director</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Arati Kumari</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td></td>\n",
       "      <td>Prospect Profiling, Inside Sales, Market Resea...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Anil Jaitly</td>\n",
       "      <td>VP Technology</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Vaidehi</td>\n",
       "      <td>Talent Acquisition Strategist</td>\n",
       "      <td></td>\n",
       "      <td>HR Consulting firms, BIG4, Top CA Consulting f...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Hephzibah Joy</td>\n",
       "      <td>Research Associate</td>\n",
       "      <td></td>\n",
       "      <td>finance, Technical Support, functional, fintec...</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Naresh</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Akshita Gujral</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td></td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>IMROZ KHAN</td>\n",
       "      <td>Recruitment Specialist</td>\n",
       "      <td></td>\n",
       "      <td>Data Analyst, Research Writer, Content Managem...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Vishakh A</td>\n",
       "      <td>Talent Acquisition Specialist</td>\n",
       "      <td></td>\n",
       "      <td>Msbi, Microsoft Power Bi, Data Warehousing, Ss...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Ashudeep yadav</td>\n",
       "      <td>Recruiter</td>\n",
       "      <td></td>\n",
       "      <td>Software Testing, It Recruitment, Software, So...</td>\n",
       "      <td>Agra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Vandhana N</td>\n",
       "      <td>Talent Search Specialist</td>\n",
       "      <td></td>\n",
       "      <td>Analytics, BI, Datawarehousing, Big Data, Hado...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Beauty Roy</td>\n",
       "      <td>Managing Consultant</td>\n",
       "      <td></td>\n",
       "      <td>Corporate Sales, claims, underwriting, Busines...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Swati Balaji</td>\n",
       "      <td>Human Resources Recruiter</td>\n",
       "      <td></td>\n",
       "      <td>Good Coomunication, Self Correspondence, Short...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Bandita Sahoo</td>\n",
       "      <td>Director</td>\n",
       "      <td></td>\n",
       "      <td>Stock Broking, Client Acquisition, dealing, Co...</td>\n",
       "      <td>Visakhapatnam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Yogkesh Kumar</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td></td>\n",
       "      <td>Data Analysis, SQL, Tableau, Power Bi, Data Mo...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Hiral</td>\n",
       "      <td>Talent Acquisition Specialist</td>\n",
       "      <td></td>\n",
       "      <td>Embedded, Unix Shell Scripting, C Programming,...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Aakash Sinha</td>\n",
       "      <td>Company HR</td>\n",
       "      <td></td>\n",
       "      <td>Analytical Skills, Communication Skills, MS Of...</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name                     desgination company  \\\n",
       "0                        HR                              HR           \n",
       "1             Ankur Agarwal             Resource Management           \n",
       "2          victorious javin            Owner of the company           \n",
       "3                 Phanindra               Company Recruiter           \n",
       "4               LOKAMBA T H             Senior Data Analyst           \n",
       "5             Jose K Kurian               Company Recruiter           \n",
       "6              Manisha Sahu             Senior HR Associate           \n",
       "7                Aamir Mian               Company Recruiter           \n",
       "8           Rohini Rajamani                         HR Lead           \n",
       "9              akash murthy          Human Resource Manager           \n",
       "10         srinivasan singh                  Hiring Manager           \n",
       "11       Nova Maria Devasia                    HR Executive           \n",
       "12                  Karthik                    HR Recruiter           \n",
       "13                  Sandhya          Consultant Recruitment           \n",
       "14                     NSMX                              HR           \n",
       "15        J LAWRENCE SUJITH             Manager Recruitment           \n",
       "16                  Eminent                        HR/Admin           \n",
       "17              Ankur Dagar    Talent Aquisition Specialist           \n",
       "18       Karthick Guruswamy               Senior Consultant           \n",
       "19                   Dileep                      HR Manager           \n",
       "20               Prashant K                           Sr HR           \n",
       "21               Hr Manager                      Hr Manager           \n",
       "22              Rekha Singh          Recruitment Consultant           \n",
       "23                       SG  Sr. HR Executive - Recruitment           \n",
       "24   Ramesh Chary Arravalli             Senior HR Executive           \n",
       "25   Blueberry Digital Labs                              HR           \n",
       "26      Abhinav Shrivastava                   Business Head           \n",
       "27             Durga Devi B         HR Generalist Assistant           \n",
       "28  RIBBUN SOFTWARE PVT LTD        Administration Executive           \n",
       "29                Jayashree                      HR Manager           \n",
       "30         Shashikant Sethy                 Head Operations           \n",
       "31            Parthasarathy                   Business Head           \n",
       "32             Krishna Sain               Company Recruiter           \n",
       "33           Venkat Ragavan                        Director           \n",
       "34             Arati Kumari                    HR Executive           \n",
       "35              Anil Jaitly                   VP Technology           \n",
       "36                  Vaidehi   Talent Acquisition Strategist           \n",
       "37            Hephzibah Joy              Research Associate           \n",
       "38                   Naresh                    Data Analyst           \n",
       "39           Akshita Gujral                    Data Analyst           \n",
       "40               IMROZ KHAN          Recruitment Specialist           \n",
       "41                Vishakh A   Talent Acquisition Specialist           \n",
       "42           Ashudeep yadav                       Recruiter           \n",
       "43               Vandhana N        Talent Search Specialist           \n",
       "44               Beauty Roy             Managing Consultant           \n",
       "45             Swati Balaji       Human Resources Recruiter           \n",
       "46            Bandita Sahoo                        Director           \n",
       "47            Yogkesh Kumar                  Human Resource           \n",
       "48                    Hiral   Talent Acquisition Specialist           \n",
       "49             Aakash Sinha                      Company HR           \n",
       "\n",
       "                                 skills_they_hire_for  \\\n",
       "0               Us English Language, Msexcel Advanced   \n",
       "1   SAP, Permissions, Designer, Marketing, Manufac...   \n",
       "2   Excel, Word, Powerpoint, Data Management, Data...   \n",
       "3                                     Data Management   \n",
       "4   Advanced Excel, Vba, Sql, Mis Reporting, Dashb...   \n",
       "5   Data Collection, Data Interpretation, Results ...   \n",
       "6   Investment Banking, Technical Support, Bpo, Kp...   \n",
       "7                                       Not Specified   \n",
       "8   BI and BA, HANA, BW, BO, Design Analytics, CMC...   \n",
       "9   Python, javascript, Java, MongoDB, AWS, Machin...   \n",
       "10  Data Analyst, Ibm Infosphere, Erwin, Oracle Ed...   \n",
       "11          Android, Java, Linux Kernel, Data Analyst   \n",
       "12  Java, C, C++, Manual Testing, Automation Tetsi...   \n",
       "13  Data Analyst, Principal Engineer, senior data ...   \n",
       "14  Survey Programming, Data Analyst, Sampling, Fi...   \n",
       "15                            Our trustable companies   \n",
       "16  Client Relationship, Technical Sales, Digital ...   \n",
       "17  Analyst, Security Engineer, System Admin, Data...   \n",
       "18  Business Development, Business Analyst, Direct...   \n",
       "19      Opportunities for freshers., Jr. Data Analyst   \n",
       "20  Data Analyst, Statistical Analysis, Data Scien...   \n",
       "21  Microsoft Word, Microsoft Excel, Search Engine...   \n",
       "22  Information Technology, Software Development, ...   \n",
       "23  Java, J2ee, .net c# asp.net sql server, oracle...   \n",
       "24  Ar Calling, Claims Adjudication, Process Assoc...   \n",
       "25  Node.js, Html, Css, Nosql, Web Designing, Web ...   \n",
       "26  Data Analytics, Data Analysis, Sales Operation...   \n",
       "27               Software Development, Data Analytics   \n",
       "28  Internet Surfing, Data Updation, Data Monitori...   \n",
       "29                                      Data Analysis   \n",
       "30                                      Not Specified   \n",
       "31              Excel, Word, Internet, English Typing   \n",
       "32         Data Science, Big Data, Big Data Analytics   \n",
       "33                                      Not Specified   \n",
       "34  Prospect Profiling, Inside Sales, Market Resea...   \n",
       "35                                      Not Specified   \n",
       "36  HR Consulting firms, BIG4, Top CA Consulting f...   \n",
       "37  finance, Technical Support, functional, fintec...   \n",
       "38                                      Not Specified   \n",
       "39                                      Not Specified   \n",
       "40  Data Analyst, Research Writer, Content Managem...   \n",
       "41  Msbi, Microsoft Power Bi, Data Warehousing, Ss...   \n",
       "42  Software Testing, It Recruitment, Software, So...   \n",
       "43  Analytics, BI, Datawarehousing, Big Data, Hado...   \n",
       "44  Corporate Sales, claims, underwriting, Busines...   \n",
       "45  Good Coomunication, Self Correspondence, Short...   \n",
       "46  Stock Broking, Client Acquisition, dealing, Co...   \n",
       "47  Data Analysis, SQL, Tableau, Power Bi, Data Mo...   \n",
       "48  Embedded, Unix Shell Scripting, C Programming,...   \n",
       "49  Analytical Skills, Communication Skills, MS Of...   \n",
       "\n",
       "                    location  \n",
       "0                 Coimbatore  \n",
       "1   Hyderabad / Secunderabad  \n",
       "2                    Gurgaon  \n",
       "3                   Warangal  \n",
       "4      Bengaluru / Bangalore  \n",
       "5                    Gurgaon  \n",
       "6      Bengaluru / Bangalore  \n",
       "7                     Mumbai  \n",
       "8      Bengaluru / Bangalore  \n",
       "9      Bengaluru / Bangalore  \n",
       "10                   Chennai  \n",
       "11                    Mumbai  \n",
       "12                   Chennai  \n",
       "13                      Pune  \n",
       "14                     Delhi  \n",
       "15                   Chennai  \n",
       "16                     Noida  \n",
       "17                     Noida  \n",
       "18                   Chennai  \n",
       "19                Trivandrum  \n",
       "20     Bengaluru / Bangalore  \n",
       "21                     Delhi  \n",
       "22     Bengaluru / Bangalore  \n",
       "23                   Chennai  \n",
       "24  Hyderabad / Secunderabad  \n",
       "25  Hyderabad / Secunderabad  \n",
       "26                    Indore  \n",
       "27     Bengaluru / Bangalore  \n",
       "28                    Jaipur  \n",
       "29                     Hosur  \n",
       "30     Bengaluru / Bangalore  \n",
       "31     Bengaluru / Bangalore  \n",
       "32     Bengaluru / Bangalore  \n",
       "33     Bengaluru / Bangalore  \n",
       "34                     Delhi  \n",
       "35                    Mumbai  \n",
       "36  Hyderabad / Secunderabad  \n",
       "37                   Gurgaon  \n",
       "38  Hyderabad / Secunderabad  \n",
       "39                     Noida  \n",
       "40                      Pune  \n",
       "41     Bengaluru / Bangalore  \n",
       "42                      Agra  \n",
       "43     Bengaluru / Bangalore  \n",
       "44                    Mumbai  \n",
       "45                   Chennai  \n",
       "46             Visakhapatnam  \n",
       "47     Bengaluru / Bangalore  \n",
       "48     Bengaluru / Bangalore  \n",
       "49                   Gurgaon  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#by using selenium and webdriver we are extract the data from website\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "#we are using chrome browser as default\n",
    "driver = webdriver.Chrome(\"Chromedriver.exe\")\n",
    "\n",
    "#nakuri website\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "\n",
    "click = driver.find_elements_by_xpath('//*[@id=\"root\"]/div[1]/div/ul/li[2]/a')[0]\n",
    "\n",
    "click.click()\n",
    "\n",
    "#nakuri website\n",
    "url = 'https://www.naukri.com/data-analyst-recruiters'\n",
    "driver.get(url)\n",
    "\n",
    "name1=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    name = driver.find_elements_by_xpath('//span[@class=\"fl ellipsis\"]')\n",
    "\n",
    "    for i in name:\n",
    "\n",
    "        name1.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    name1.append('No details available')\n",
    "\n",
    "print(len(name1))\n",
    "name1\n",
    "\n",
    "\n",
    "\n",
    "desgination1=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    desgination = driver.find_elements_by_xpath('//span[@class=\"ellipsis clr\"]')\n",
    "\n",
    "    for i in desgination:\n",
    "\n",
    "        desgination1.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    desgination1.append('No details available')\n",
    "\n",
    "print(len(desgination1))\n",
    "desgination1\n",
    "\n",
    "company1 = []\n",
    "try:\n",
    "\n",
    "    company = driver.find_elements_by_xpath('//i[@class=\"cmpIcn\"]')\n",
    "\n",
    "    for i in company:\n",
    "\n",
    "        company1.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    company1.append('No details available')\n",
    "\n",
    "print(len(company1))\n",
    "company1\n",
    "\n",
    "\n",
    "\n",
    "skills_they_hire_for1 = []\n",
    "try:\n",
    "\n",
    "    skills_they_hire_for = driver.find_elements_by_xpath('//div[@class=\"hireSec highlightable\"]')\n",
    "\n",
    "    for i in skills_they_hire_for:\n",
    "\n",
    "        skills_they_hire_for1.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    skills_they_hire_for1.append('No details available')\n",
    "\n",
    "print(len(skills_they_hire_for1))\n",
    "skills_they_hire_for1\n",
    "\n",
    "location1 = []\n",
    "try:\n",
    "\n",
    "    location = driver.find_elements_by_xpath('//small[@class=\"ellipsis\"]')\n",
    "\n",
    "    for i in location:\n",
    "\n",
    "        location1.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    location1.append('No details available')\n",
    "\n",
    "print(len(location1))\n",
    "location1\n",
    "\n",
    "df=pd.DataFrame({})\n",
    "df['name']=name1\n",
    "df['desgination']=desgination1\n",
    "df['company']=company1\n",
    "df['skills_they_hire_for']=skills_they_hire_for1\n",
    "df['location']=location1\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Scrape the details of Highest selling novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>author</th>\n",
       "      <th>book name</th>\n",
       "      <th>volume sales</th>\n",
       "      <th>publisher</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank            author                                          book name  \\\n",
       "0     1        Brown, Dan                                  Da Vinci Code,The   \n",
       "1     2     Rowling, J.K.               Harry Potter and the Deathly Hallows   \n",
       "2     3     Rowling, J.K.           Harry Potter and the Philosopher's Stone   \n",
       "3     4     Rowling, J.K.          Harry Potter and the Order of the Phoenix   \n",
       "4     5      James, E. L.                               Fifty Shades of Grey   \n",
       "..  ...               ...                                                ...   \n",
       "95   96    Harris, Robert                                          Ghost,The   \n",
       "96   97     Oliver, Jamie                     Happy Days with the Naked Chef   \n",
       "97   98  Collins, Suzanne              Hunger Games,The:Hunger Games Trilogy   \n",
       "98   99      Pelzer, Dave  Lost Boy,The:A Foster Child's Search for the L...   \n",
       "99  100     Oliver, Jamie  Jamie's Ministry of Food:Anyone Can Learn to C...   \n",
       "\n",
       "   volume sales        publisher                        genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using selenium for webscraping and also using the exception handling\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "#chromeweb browser is used\n",
    "driver = webdriver.Chrome(\"Chromedriver.exe\")\n",
    "\n",
    "#guardian website is used\n",
    "url = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "#getting all the value\n",
    "rank=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    names=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[1]\")\n",
    "\n",
    "    for i in names:\n",
    "\n",
    "        rank.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    rank.append('No details available')\n",
    "\n",
    "print(len(rank))\n",
    "\n",
    "\n",
    "book_name=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    names=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[2]\")\n",
    "\n",
    "    for i in names:\n",
    "\n",
    "        book_name.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    book_name.append('No details available')\n",
    "\n",
    "print(len(book_name))\n",
    "\n",
    "volume_sales=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    names=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[4]\")\n",
    "\n",
    "    for i in names:\n",
    "\n",
    "        volume_sales.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    volume_sales.append('No details available')\n",
    "\n",
    "print(len(volume_sales))\n",
    "\n",
    "author = []\n",
    "try:\n",
    "\n",
    "    names=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[3]\")\n",
    "\n",
    "    for i in names:\n",
    "\n",
    "        author.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    author.append('No details available')\n",
    "\n",
    "print(len(author))\n",
    "\n",
    "publisher = []\n",
    "try:\n",
    "\n",
    "    names=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[5]\")\n",
    "\n",
    "    for i in names:\n",
    "\n",
    "        publisher.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    publisher.append('No details available')\n",
    "\n",
    "print(len(publisher))\n",
    "\n",
    "genre = []\n",
    "try:\n",
    "\n",
    "    names=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[6]\")\n",
    "\n",
    "    for i in names:\n",
    "\n",
    "        genre.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    genre.append('No details available')\n",
    "\n",
    "print(len(genre))\n",
    "\n",
    "rank\n",
    "author\n",
    "book_name\n",
    "volume_sales\n",
    "publisher\n",
    "genre\n",
    "#dataframe is used\n",
    "df = pd.DataFrame({})\n",
    "df['rank'] = rank\n",
    "df['author'] = author\n",
    "df['book name'] = book_name\n",
    "df['volume sales'] = volume_sales\n",
    "df['publisher'] = publisher\n",
    "df['genre'] = genre\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Scrape the details most watched tv series of all time from imdb.com.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year_span</th>\n",
       "      <th>span</th>\n",
       "      <th>runtime</th>\n",
       "      <th>rate1</th>\n",
       "      <th>vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1,824,154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>864,426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>874,780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>262,783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>224,151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>44,587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>55,094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8</td>\n",
       "      <td>167,867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>34,903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>191,547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name    year_span                      span  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "    runtime rate1       vote  \n",
       "0    57 min   9.3  1,824,154  \n",
       "1    51 min   8.7    864,426  \n",
       "2    44 min   8.2    874,780  \n",
       "3    60 min   7.6    262,783  \n",
       "4    43 min   7.6    224,151  \n",
       "..      ...   ...        ...  \n",
       "95   42 min   7.5     44,587  \n",
       "96   50 min   7.8     55,094  \n",
       "97   42 min     8    167,867  \n",
       "98   45 min   7.1     34,903  \n",
       "99  572 min   8.6    191,547  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using selenium for webscraping and also using the exception handling\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "#chromeweb browser is used\n",
    "driver = webdriver.Chrome('Chromedriver.exe')\n",
    "\n",
    "#imdb website is used\n",
    "url = 'https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)\n",
    "\n",
    "#name is webscraped\n",
    "name = driver.find_elements_by_xpath('//*[@id=\"main\"]/div/div[3]/div[3]/div/div[2]/h3/a')\n",
    "\n",
    "name\n",
    "\n",
    "name1 = []\n",
    "for i in name:\n",
    "    name1.append(i.text)\n",
    "name1\n",
    "\n",
    "#year span is webscraped\n",
    "year_span = driver.find_elements_by_xpath('//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "\n",
    "year_span1 = []\n",
    "for i in year_span:\n",
    "    year_span1.append(i.text)\n",
    "year_span1\n",
    "\n",
    "#span is webscraped\n",
    "span = driver.find_elements_by_xpath('//span[@class=\"genre\"]')\n",
    "\n",
    "span1 = []\n",
    "for i in span:\n",
    "    span1.append(i.text)\n",
    "span1\n",
    "\n",
    "#runtime is webscraped\n",
    "runtime = driver.find_elements_by_xpath('//span[@class=\"runtime\"]')\n",
    "\n",
    "runtime1 = []\n",
    "for i in runtime:\n",
    "    runtime1.append(i.text)\n",
    "runtime1\n",
    "\n",
    "#rate is webscraped\n",
    "rate = driver.find_elements_by_xpath('//div[@class=\"ipl-rating-star small\"]')\n",
    "\n",
    "rate1 = []\n",
    "for i in rate:\n",
    "    rate1.append(i.text)\n",
    "rate1\n",
    "\n",
    "#vote is webscraped\n",
    "vote = driver.find_elements_by_name('nv')\n",
    "\n",
    "vote\n",
    "\n",
    "vote1 = []\n",
    "for i in vote:\n",
    "    vote1.append(i.text)\n",
    "vote1\n",
    "\n",
    "print(len(name1))\n",
    "print(len(year_span1))\n",
    "print(len(span1))\n",
    "print(len(runtime1))\n",
    "print(len(rate1))\n",
    "print(len(vote1))\n",
    "\n",
    "#data frame is used\n",
    "df = pd.DataFrame({})\n",
    "df['name'] = name1\n",
    "df['year_span'] = year_span1\n",
    "df['span'] = span1\n",
    "df['runtime'] = runtime1\n",
    "df['rate1'] = rate1\n",
    "df['vote'] = vote1\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10  Details of Datasets from UCI machine learning repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589\n",
      "589\n",
      "589\n",
      "589\n",
      "589\n",
      "589\n",
      "589\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>data_type</th>\n",
       "      <th>task</th>\n",
       "      <th>attribute_type</th>\n",
       "      <th>no_of_instance</th>\n",
       "      <th>no_of_attribute</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>in-vehicle coupon recommendation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>12684</td>\n",
       "      <td>23</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Gait Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>48</td>\n",
       "      <td>321</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Synchronous Machine Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dataset_name      data_type                  task  \\\n",
       "1                               Abalone  Multivariate        Classification    \n",
       "2                                 Adult  Multivariate        Classification    \n",
       "3                             Annealing  Multivariate        Classification    \n",
       "4          Anonymous Microsoft Web Data                 Recommender-Systems    \n",
       "5                            Arrhythmia  Multivariate        Classification    \n",
       "..                                  ...            ...                   ...   \n",
       "584    in-vehicle coupon recommendation  Multivariate        Classification    \n",
       "585                 Gait Classification  Multivariate        Classification    \n",
       "586           Wikipedia Math Essentials   Time-Series            Regression    \n",
       "587           Wikipedia Math Essentials   Time-Series            Regression    \n",
       "588        Synchronous Machine Data Set  Multivariate            Regression    \n",
       "\n",
       "                  attribute_type no_of_instance no_of_attribute   year  \n",
       "1    Categorical, Integer, Real           4177               8   1995   \n",
       "2          Categorical, Integer          48842              14   1996   \n",
       "3    Categorical, Integer, Real            798              38          \n",
       "4                   Categorical          37711             294   1998   \n",
       "5    Categorical, Integer, Real            452             279   1998   \n",
       "..                           ...            ...             ...    ...  \n",
       "584                                      12684              23   2020   \n",
       "585                        Real             48             321   2020   \n",
       "586                        Real            731            1068   2021   \n",
       "587                        Real            731            1068   2021   \n",
       "588                        Real            557               5   2021   \n",
       "\n",
       "[588 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using selenium for webscraping and also using the exception handling\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "#chromeweb browser is used\n",
    "driver = webdriver.Chrome(\"Chromedriver.exe\")\n",
    "\n",
    "#ics website is used\n",
    "url = 'https://archive.ics.uci.edu/'\n",
    "driver.get(url)\n",
    "\n",
    "#button is clicked\n",
    "button = driver.find_elements_by_xpath('/html/body/table[1]/tbody/tr/td[2]/span[2]/a/font/b')[0]\n",
    "\n",
    "button.click()\n",
    "\n",
    "#value are webscraped\n",
    "dataset_name=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    names=driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[1]')\n",
    "\n",
    "    for i in names:\n",
    "\n",
    "        dataset_name.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    dataset_name.append('No details available')\n",
    "\n",
    "print(len(dataset_name))\n",
    "\n",
    "\n",
    "data_type1=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    data_type=driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]')\n",
    "\n",
    "    for i in data_type:\n",
    "\n",
    "        data_type1.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    data_type1.append('No details available')\n",
    "\n",
    "print(len(data_type1))\n",
    "\n",
    "task1=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    task=driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]')\n",
    "\n",
    "    for i in task:\n",
    "\n",
    "        task1.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    task1.append('No details available')\n",
    "\n",
    "print(len(task1))\n",
    "\n",
    "\n",
    "attribute_type1=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    attribute_type=driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]')\n",
    "\n",
    "    for i in attribute_type:\n",
    "\n",
    "        attribute_type1.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    attribute_type1.append('No details available')\n",
    "\n",
    "print(len(attribute_type1))\n",
    "\n",
    "\n",
    "no_of_instance1=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    no_of_instance=driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]/p')\n",
    "\n",
    "    for i in no_of_instance:\n",
    "\n",
    "        no_of_instance1.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    no_of_instance1.append('No details available')\n",
    "\n",
    "print(len(no_of_instance1))\n",
    "\n",
    "\n",
    "year1=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    year=driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]/p')\n",
    "\n",
    "    for i in year:\n",
    "\n",
    "        year1.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    year1.append('No details available')\n",
    "\n",
    "print(len(year1))\n",
    "\n",
    "\n",
    "no_of_attribute1=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    no_of_attribute=driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]/p')\n",
    "\n",
    "    for i in no_of_attribute:\n",
    "\n",
    "        no_of_attribute1.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    no_of_attribute1.append('No details available')\n",
    "\n",
    "print(len(no_of_attribute))\n",
    "\n",
    "#dataframe is used\n",
    "\n",
    "df=pd.DataFrame({})\n",
    "df['dataset_name']=dataset_name\n",
    "df['data_type']=data_type1\n",
    "df['task']=task1\n",
    "df['attribute_type']=attribute_type1\n",
    "df['no_of_instance']=no_of_instance1\n",
    "df['no_of_attribute']=no_of_attribute1\n",
    "df['year']=year1\n",
    "\n",
    "df\n",
    "\n",
    "df = df.drop(labels=0, axis=0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
